{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2830068,"sourceType":"datasetVersion","datasetId":1731100},{"sourceId":8456473,"sourceType":"datasetVersion","datasetId":5040130},{"sourceId":10032943,"sourceType":"datasetVersion","datasetId":4570082}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Defining Artist \"Eras\" Through Lyrical Analysis\n\nIf you have a Taylor Swift fan in your life like I do, you've probably heard about the **Eras Tour** by now. This [record-breaking](https://www.newsweek.com/taylor-swift-eras-tour-broke-18-records-1996679#:~:text=The%20Eras%20Tour%20broke%20the,concert%20tour%20of%20all%20time.) worldwide tour captivated \"Swifties\" around the globe, featuring songs from every Taylor Swift album, dating all the way back to her 2006 debut.\n\nAs Taylor has grown, so has her music. Her life experiences are reflected in her lyrics, inspiring fans to define distinct musical \"eras\" based on the themes and emotional undertones in each of her albums. Each era tells a different story, shaped by the time in which it was created.\n\nThis leads us to some interesting questions:\n\n- Do other artists also have recognizable eras?\n- Can we identify these eras just by analyzing lyrics?\n- How do eras evolve? Do they shift sharply from album to album, or more gradually over time?\n\nIn this notebook, we’ll explore those questions using AI-powered text analysis. We'll cluster songs based on lyrical similarity, characterize the themes in each cluster, and compare those groupings to traditional ways of organizing music (like albums or release dates) to see how well they align.\n","metadata":{}},{"cell_type":"markdown","source":"## Setup\n\nReview datasets and install required packages, including the Gemini API Python SDK.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:40:28.684923Z","iopub.execute_input":"2025-04-20T17:40:28.685317Z","iopub.status.idle":"2025-04-20T17:40:29.091062Z","shell.execute_reply.started":"2025-04-20T17:40:28.685282Z","shell.execute_reply":"2025-04-20T17:40:29.088902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab kfp &>/dev/null  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\" \"chromadb==0.6.3\" &>/dev/null\n!pip install scikit-learn &>/dev/null","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:40:29.093123Z","iopub.execute_input":"2025-04-20T17:40:29.093670Z","iopub.status.idle":"2025-04-20T17:41:18.619781Z","shell.execute_reply.started":"2025-04-20T17:40:29.093636Z","shell.execute_reply":"2025-04-20T17:41:18.618203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:41:18.622175Z","iopub.execute_input":"2025-04-20T17:41:18.622515Z","iopub.status.idle":"2025-04-20T17:41:20.204927Z","shell.execute_reply.started":"2025-04-20T17:41:18.622485Z","shell.execute_reply":"2025-04-20T17:41:20.203834Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Set up your API key\n\nTo run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n\nIf you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n\nTo make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:41:20.206422Z","iopub.execute_input":"2025-04-20T17:41:20.206957Z","iopub.status.idle":"2025-04-20T17:41:20.771964Z","shell.execute_reply.started":"2025-04-20T17:41:20.206921Z","shell.execute_reply":"2025-04-20T17:41:20.770883Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n\n![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)","metadata":{}},{"cell_type":"markdown","source":"## Data\n\nThree datasets are loaded into this notebook by default. Each one contains the lyrics for a particular artist's discography.\n\nThe artists include:\n\n- Taylor Swift\n- Bob Dylan\n- Kendrick Lamar\n\nTo ensure the datasets are correctly loaded, we can check the `/kaggle/input` directory","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:41:20.772915Z","iopub.execute_input":"2025-04-20T17:41:20.773175Z","iopub.status.idle":"2025-04-20T17:41:20.803870Z","shell.execute_reply.started":"2025-04-20T17:41:20.773152Z","shell.execute_reply":"2025-04-20T17:41:20.802650Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If you see filepaths for `.csv` files, you're good to go. \n\nEach of the datasets contains the data that we need, but they all have slightly different ways of storing it.\n\nBelow we have a code block for each artist. \nThe code block creates a DataFrame using the dataset for that artist and it defines column names used in that dataset. \n\nYou should pick one artist to move forward with in this notebook.\nTo use that artist, simply uncomment their corresponding code block before continuing.\n\nBy default, **Taylor Swift** is uncommented.\n\nYou may always re-run the notebook with a different artist later.","metadata":{}},{"cell_type":"markdown","source":"First, define common columns that are used no matter which dataset is selected","metadata":{}},{"cell_type":"code","source":"# Common columns - Leave these uncommented\ncluster_col = 'cluster'\nyear_col = 'release_year'\nembeddings_col = 'embeddings'\nvibe_col = 'vibe'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:41:20.805103Z","iopub.execute_input":"2025-04-20T17:41:20.805469Z","iopub.status.idle":"2025-04-20T17:41:20.843773Z","shell.execute_reply.started":"2025-04-20T17:41:20.805427Z","shell.execute_reply":"2025-04-20T17:41:20.842669Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Taylor Swift","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/taylor-swift-released-song-discography-genius/ts_discography_released.csv')\ntitle_col='song_title'\nalbum_col='album_title'\nlyrics_col='song_lyrics'\n\n# Exclude special editions albums that would result in repeated lyrics\nexclude = ['1989 (Deluxe)', 'Fearless (Platinum Edition)', 'Red (Deluxe Version)', \n           'Speak Now (Deluxe)', 'The Taylor Swift Holiday Collection - EP']\ndf = df[~df[album_col].isin(exclude)]\n\n# Create a release year column\ndf['release_date_dt'] = pd.to_datetime(df['song_release_date'])\ndf[year_col] = df['release_date_dt'].dt.year","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:41:20.867571Z","iopub.execute_input":"2025-04-20T17:41:20.867923Z","iopub.status.idle":"2025-04-20T17:41:20.882899Z","shell.execute_reply.started":"2025-04-20T17:41:20.867894Z","shell.execute_reply":"2025-04-20T17:41:20.881676Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Bob Dylan","metadata":{}},{"cell_type":"code","source":"# df=pd.read_csv('/kaggle/input/bob-dylan-songs/clear.csv')\n# title_col='title'\n# album_col='album'\n# lyrics_col='lyrics'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:41:20.844979Z","iopub.execute_input":"2025-04-20T17:41:20.845439Z","iopub.status.idle":"2025-04-20T17:41:20.864059Z","shell.execute_reply.started":"2025-04-20T17:41:20.845405Z","shell.execute_reply":"2025-04-20T17:41:20.862832Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Kendrick Lamar","metadata":{}},{"cell_type":"code","source":"# df=pd.read_csv('/kaggle/input/kendrick-lamar-albumslyrics-dataset/discog_data.csv')\n# title_col='track_name'\n# album_col='album'\n# lyrics_col='lyrics'\n\n# # Create a release year column\n# df['release_date_dt'] = pd.to_datetime(df['release_date'])\n# df[year_col] = df['release_date_dt'].dt.year","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:52.198589Z","iopub.execute_input":"2025-04-20T17:42:52.198951Z","iopub.status.idle":"2025-04-20T17:42:52.218560Z","shell.execute_reply.started":"2025-04-20T17:42:52.198924Z","shell.execute_reply":"2025-04-20T17:42:52.216903Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Sometimes these datasets will contain minor releases that only contain a few songs.\n\nTo get the best results possible, remove these songs from the dataframe before starting.","metadata":{}},{"cell_type":"code","source":"# Filter out any albums with fewer the 5 songs\nalbum_counts = df[album_col].value_counts()\nvalid_albums = album_counts[album_counts >= 5].index\ndf = df[df[album_col].isin(valid_albums)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:52.252432Z","iopub.execute_input":"2025-04-20T17:42:52.252749Z","iopub.status.idle":"2025-04-20T17:42:52.267704Z","shell.execute_reply.started":"2025-04-20T17:42:52.252721Z","shell.execute_reply":"2025-04-20T17:42:52.266357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, let's look at the data we're given. Feel free to explore the dataframe more before continuing!","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:52.220619Z","iopub.execute_input":"2025-04-20T17:42:52.220974Z","iopub.status.idle":"2025-04-20T17:42:52.250729Z","shell.execute_reply.started":"2025-04-20T17:42:52.220944Z","shell.execute_reply":"2025-04-20T17:42:52.249762Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create Embeddings\n\n**Embeddings** are numerical representations of data that are designed to capture the underlying meaning of that data.\n\nBelow, we'll create a function to generate embeddings for our song lyrics using the Gemini API.\n\n**Note**: Not all embeddings are created equal. There are specific types of embeddings for different use cases. Notice that we use the `clustering` type in our example because we want to identify groups of lyrics that are semantically similar.\n\nFor more information on embeddings and their types, see [here](https://ai.google.dev/gemini-api/docs/embeddings).","metadata":{}},{"cell_type":"code","source":"from google.api_core import retry\nimport tqdm\nfrom tqdm.rich import tqdm as tqdmr\nimport warnings\n\ntqdmr.pandas()\n\n# Filter the experimental warning\nwarnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n\n# Define a helper to retry when per-minute quota is reached.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n@retry.Retry(predicate=is_retriable, timeout=300.0)\ndef embed_lyrics(lyrics: list[str]) -> list[list[float]]:\n    # Helper to chunk the lyrics (Max 100 per request)\n    def chunks(lst, n):\n        for i in range(0, len(lst), n):\n            yield lst[i:i + n]\n\n    all_embeddings = []\n    for batch in chunks(lyrics, 100):\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=batch,\n            config=types.EmbedContentConfig(\n                task_type=\"clustering\",\n            ),\n        )\n\n        # Extract the embedding vector from the responses\n        batch_embeddings = [embedding.values for embedding in response.embeddings]\n\n        # Add to the total\n        all_embeddings.extend(batch_embeddings)\n\n    return all_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:52.269373Z","iopub.execute_input":"2025-04-20T17:42:52.269789Z","iopub.status.idle":"2025-04-20T17:42:52.482573Z","shell.execute_reply.started":"2025-04-20T17:42:52.269749Z","shell.execute_reply":"2025-04-20T17:42:52.481571Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's create the embeddings and see what they actually look like! \n\n**Note**: It's normal for this step to take a couple seconds","metadata":{}},{"cell_type":"code","source":"# Create the embeddings and add to our DataFrame\nembeddings = embed_lyrics(df[lyrics_col].tolist())\ndf[embeddings_col] = embeddings\n\n# View the embeddings\ndf.loc[:,[title_col, album_col, embeddings_col]].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:52.483809Z","iopub.execute_input":"2025-04-20T17:42:52.484440Z","iopub.status.idle":"2025-04-20T17:42:53.528502Z","shell.execute_reply.started":"2025-04-20T17:42:52.484402Z","shell.execute_reply":"2025-04-20T17:42:53.527232Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can see that the embeddings are a vector. We can't tell much from the numbers alone, so it would helpful if we could visualize this data.\n\nLet's see how many dimensions each of these vectors contains.","metadata":{}},{"cell_type":"code","source":"len(df[embeddings_col][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:53.529557Z","iopub.execute_input":"2025-04-20T17:42:53.529965Z","iopub.status.idle":"2025-04-20T17:42:53.536775Z","shell.execute_reply.started":"2025-04-20T17:42:53.529928Z","shell.execute_reply":"2025-04-20T17:42:53.535698Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Alright, too many for us to visualize.\n\nThankfully, we can use **Dimensionality Reduction** to reduce the vectors to 2 dimensions.","metadata":{}},{"cell_type":"markdown","source":"## Dimensionality Reduction\n\nTo perform dimensionality reduction, we'll be using something called [**T-distributed Stochastic Neighbor Embedding**](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) (TSNE).\n\nTSNE is going to preserve the relationship between our data points as much as possible while reducing their dimensionality. ","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\n\n# Convert the embeddings column to a list\nembeddings_list = np.array(df[embeddings_col].to_list(), dtype=np.float32)\n\n# Call the TSNE functions on the list\ntsne = TSNE(random_state=0, n_iter=1000)\ntsne_results = tsne.fit_transform(embeddings_list)\n\n# Add TSNE results to the DataFrame\ndf['TSNE1'] = tsne_results[:, 0]\ndf['TSNE2'] = tsne_results[:, 1]\n\ndf[[title_col, 'TSNE1', 'TSNE2']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:53.538217Z","iopub.execute_input":"2025-04-20T17:42:53.538619Z","iopub.status.idle":"2025-04-20T17:42:55.247990Z","shell.execute_reply.started":"2025-04-20T17:42:53.538578Z","shell.execute_reply":"2025-04-20T17:42:55.246800Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Great! Now each embedding is represented using two dimensions (TSNE1, TSNE2). \n\nFrom here, we can plot these points on a graph to actually visualize the embeddings we've created.\n\nWe'll sort the embeddings by album for now to see if we can spot any trends.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Plot the 2-dimensional data points using Seaborn\nfig, ax = plt.subplots(figsize=(8,6))\nsns.set_style('darkgrid', {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\nsns.scatterplot(data=df, x='TSNE1', y='TSNE2', hue=album_col, palette='hls')\nsns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\nplt.title('Song Lyric Embeddings by Album');\nplt.xlabel('TSNE1');\nplt.ylabel('TSNE2');\nplt.axis('equal')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:55.249085Z","iopub.execute_input":"2025-04-20T17:42:55.249728Z","iopub.status.idle":"2025-04-20T17:42:56.323331Z","shell.execute_reply.started":"2025-04-20T17:42:55.249697Z","shell.execute_reply":"2025-04-20T17:42:56.321296Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"See if you can draw any conclusions from the graph. Are there any clusters of dots with the same color?\n\nIt's alright if you don't see any meaningful trends. This may give us a hint that the artist we're looking\nat uses similar lyrics for each of their albums. \n\nIn the next step, we'll attempt to define our own groups of similar data points to see if they could be\nworthy of an \"era\".","metadata":{}},{"cell_type":"markdown","source":"## Clustering Embeddings\n\nRecall that when we initially created these embeddings the embedding type we chose was `clustering`. \n\nThat means that we should be able to cluster our data points together based on semantic simlarity.\n\nWe will use [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) to do this. \n\nKMeans is an algorithm that will calculate \"clusters\" from our embeddings. These \"clusters\" represent semantic groupings of the original data we embedded.","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\n# The number of clusters to create\n# This value is great for experimentation:\n#   - a low value will provide more concrete and distinct groupings\n#   - a high value will provide more nuanced groupings that may have some overlap\nnum_clusters=3\n\n# Call KMeans on our 2-dimensional data points\nkmeans_model = KMeans(n_clusters=num_clusters, random_state=1, n_init='auto').fit(embeddings_list)\nlabels = kmeans_model.fit_predict(embeddings_list)\n\n# Propagate the results to a \"Cluster\" column in our DataFrame\ndf[cluster_col] = labels\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:01:36.412117Z","iopub.execute_input":"2025-04-20T18:01:36.412595Z","iopub.status.idle":"2025-04-20T18:01:36.456059Z","shell.execute_reply.started":"2025-04-20T18:01:36.412480Z","shell.execute_reply":"2025-04-20T18:01:36.454719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the Clusters using Seaborn\nfig, ax = plt.subplots(figsize=(8,6)) # Set figsize\nsns.set_style('darkgrid', {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\nsns.scatterplot(data=df, x='TSNE1', y='TSNE2', hue=cluster_col, palette='magma')\nsns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\nplt.title('Song Lyric Embeddings by Cluster');\nplt.xlabel('TSNE1');\nplt.ylabel('TSNE2');\nplt.axis('equal')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:56.478419Z","iopub.execute_input":"2025-04-20T17:42:56.478776Z","iopub.status.idle":"2025-04-20T17:42:57.099498Z","shell.execute_reply.started":"2025-04-20T17:42:56.478748Z","shell.execute_reply":"2025-04-20T17:42:57.098433Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We've should be seeing more visible groupings now thanks to KMeans.\n\nSo we've verified that we can create cluster of semantically similar songs.\n\nHowever, we still don't know what these clusters really represent, or whether they can constitute an \"era\" in the artist's discography\n\nWe'll attempt to define them more concretely in the next section.","metadata":{}},{"cell_type":"markdown","source":"## Defining the Clusters using AI","metadata":{}},{"cell_type":"markdown","source":"Unless you're a diehard fan, you're not going to be able to look at all the songs in a particular cluster and identify what they have in common.\n\nYou would have to read through and analyze all of the lyrics in a particular cluster in a tedious and painstaking process.\n\nThankfully, we can have an AI model do this for us.\n\nBelow, we create a [few-shot prompt](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/few-shot-examples) to have an AI model read the lyrics and identify what we're looking for.","metadata":{}},{"cell_type":"code","source":"few_shot_prompt = \"\"\"\nYou are an expert on music and lyrics who specializes in identifying commonalities between\ngroups of song lyrics. \n\nThese commonalities can range from concrete elements like word choice, tone, and frequency to more\nmore abstract ideas such as overarching themes, emotional undertones, or the general “feel” of the lyrics.\n\nYou will be provided with a group of song lyrics that were clustered together using an AI model based on their embeddings.\n\nYour task is to:\n1) Read the lyrics thoroughly.\n2) Infer and explain what characteristics these lyrics share that may have contributed to their grouping.\n\nThe lyrics for each song will be separated by a short line of dashes: \"---\"\n\nThe lyrics for any given song may contain other line breaks. These line breaks do not indicate a new\nsong has started. Only look for the line of 3 dashes.\n\nYour response should be returned as a valid JSON containing 3 fields:\n\ndescription: A thoughtful and concise summary of the shared characteristics of the lyrics and why\n             you think that they were originally grouped together.\nvibe: A word or short phrase that captures the overall mood, theme, or vibe of the lyrics.\n      Be creative and descriptive with this field.\nline: A line of short group of lines from the lyrics that exemplifies the overall vibe that you\n      determined for the group of lyrics\n\nEXAMPLE:\nCluster Lyrics:\nLittle darling, the smile’s returning to their faces.\nHere comes the sun, and I say, it’s all right.\n\n---\n\nBut you gotta keep your head up, oh oh\nAnd you can let your hair down, eh eh\n\n---\n\nThe dog days are over\nThe dog days are done\n\n---\n\nYeah, there's always been a rainbow\nHangin' over your head\n\nJSON RESPONSE:\n{\n\"description\": \"The lyrics share a common emotional theme of the transition from struggle or darkness into relief, light, or freedom. They're not just hopeful — they're reaffirming, as if acknowledging that something difficult has been endured and now there is a release, a breath, a return of joy or peace.\",\n\"vibe\": \"Optimistic and Hopeful\",\n\"line\": \"you gotta keep your head up\"\n}\n\nEXAMPLE:\nCluster Lyrics: \nI hurt myself today\nTo see if I still feel\n\n---\n\nHello darkness, my old friend\nI've come to talk with you again\n\n---\n\nI’m just a little bit caught in the middle\nLife is a maze and love is a riddle\n\n---\n\nSometimes I wish it would rain\nSo no one could see me cry\n\nJSON RESPONSE:\n{\n  \"description\": \"These lyrics reflect introspection, emotional vulnerability, and a deep sense of isolation or sadness. The themes often revolve around pain, confusion, and quiet suffering, conveyed through stark and honest expressions of emotional struggle.\",\n  \"vibe\": \"Melancholic and Reflective\",\n  \"line\": \"Hello darkness, my old friend\"\n}\n\nACTUAL:\nCluster Lyrics:\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:57.100681Z","iopub.execute_input":"2025-04-20T17:42:57.100970Z","iopub.status.idle":"2025-04-20T17:42:57.106251Z","shell.execute_reply.started":"2025-04-20T17:42:57.100947Z","shell.execute_reply":"2025-04-20T17:42:57.105187Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You might notice that we ask for our response in `json` format. We do this to make it easier to process and re-use the data from the response later in the notebook.\n\nWe can further enforce this output structure by creating a dictionary in Python and passing it to the model when we generate our response, as seen below.","metadata":{}},{"cell_type":"code","source":"import typing_extensions as typing\n\n# The object used to parse the model output\nclass ClusterSummary(typing.TypedDict):\n    description: str\n    vibe: str\n    line: str\n\n# Prints a ClusterSummary\ndef print_cluster_summary(summary: ClusterSummary) -> None:\n    # Note: The \"number\" field will be added after the response is generated\n    md_output = f\"\"\"\n**Cluster**: {summary[\"number\"]}\n\n- **Description**: {summary['description']}\n- **Vibe**: {summary['vibe']}\n- **Line**: {summary['line']}\n\"\"\"\n    display(Markdown(md_output))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:57.107282Z","iopub.execute_input":"2025-04-20T17:42:57.107649Z","iopub.status.idle":"2025-04-20T17:42:57.129242Z","shell.execute_reply.started":"2025-04-20T17:42:57.107619Z","shell.execute_reply":"2025-04-20T17:42:57.128077Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, create the function that calls the model using the prompt and lyrics from the cluster.","metadata":{}},{"cell_type":"code","source":"import random, json, enum\nfrom IPython.display import display, Markdown\n\n# Summarizes a cluster into its ClusterFeatures\ndef summarize_cluster(df, cluster_num, max_lyrics=40):\n    lyrics_list = df[df[cluster_col] == cluster_num][lyrics_col].tolist()\n    cluster_lyrics = \"\\n\\n---\\n\\n\".join(random.sample(lyrics_list, min(len(lyrics_list), max_lyrics)))\n\n    structured_output_config = types.GenerateContentConfig(\n      response_mime_type=\"application/json\", # Generate JSON output\n      response_schema=ClusterSummary,        # Use our defined schema\n  )\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[few_shot_prompt, cluster_lyrics],\n        config=structured_output_config,\n    )\n    \n    return response.parsed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:57.130392Z","iopub.execute_input":"2025-04-20T17:42:57.130756Z","iopub.status.idle":"2025-04-20T17:42:57.152009Z","shell.execute_reply.started":"2025-04-20T17:42:57.130727Z","shell.execute_reply":"2025-04-20T17:42:57.150966Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Call the function on each of our clusters.","metadata":{}},{"cell_type":"code","source":"# Save and print the cluster summaries\ncluster_summaries = []\nfor cluster_num in range(num_clusters):\n    # Summarize the cluster\n    summary = summarize_cluster(df, cluster_num)\n    summary[\"number\"] = str(cluster_num) # Add the cluster number to the ClusterSummary\n    \n    # Print the ClusterSummary\n    print_cluster_summary(summary)\n\n    # Add to array for future usage\n    cluster_summaries.append(summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:42:57.152954Z","iopub.execute_input":"2025-04-20T17:42:57.153229Z","iopub.status.idle":"2025-04-20T17:43:01.548515Z","shell.execute_reply.started":"2025-04-20T17:42:57.153206Z","shell.execute_reply":"2025-04-20T17:43:01.547473Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We have now defined each of our clusters! \n\nDepending on the artist you selected and the number of clusters you created, your results in these descriptions may vary. You're encouraged to try different combinations of parameters to achieve the best result possible!","metadata":{}},{"cell_type":"markdown","source":"## Visualizing Cluster Relationships\n\nNow that we have defined the clusters we can start to explore the relationships these clusters have with other parts of the data.\n\nMore specifically, we'll be looking at how clusters relate to albums and how cluster usage tends to change over time.","metadata":{}},{"cell_type":"markdown","source":"### Album-Cluster Relationship\n\nIn this section, we'll explore how an artist's albums relate to their lyrical clusters.\n\nWe'll aim to answer questions like:\n\n- Do albums tend to contain songs from the same cluster, or are they more evenly spread across multiple clusters?\n- Alternatively, do clusters tend to correspond to a specific album, or are they more mixed?\n- Are there any broader patterns we can identify, such as a group of albums sharing a similar cluster makeup?\n\nBy analyzing these relationships, we can begin to understand whether artists group similar lyrical themes within albums, if those themes evolve more gradually over time, or if those themes have no meaningful change through the discography at all.\n","metadata":{}},{"cell_type":"markdown","source":"Define functions to visualize the album-cluster relationship:","metadata":{}},{"cell_type":"code","source":"# Add the \"vibe\" of each cluster as a column - Used as an axis when visualizing\ndf[vibe_col] = [cluster_summaries[i][\"vibe\"] for i in df[cluster_col]]\n\n# Function to plot the composition of an album or cluster using a pie chart\ndef composition_pie_chart(wholeCol, piecesCol):\n    items = df[wholeCol].unique()\n    \n    for item in items:\n        item_df = df[df[wholeCol] == item]\n        counts = item_df[piecesCol].value_counts().sort_index()\n\n        plt.figure(figsize=(5, 5))\n        plt.pie(counts, labels=counts.index, autopct=\"%1.1f%%\", startangle=140)\n        plt.title(f\"{item}\")\n        plt.axis(\"equal\")\n        plt.show()\n\n\n# Function to plot the shared relationship using a pivot table\ndef composition_pivot_table():\n    pivot = df.pivot_table(index=album_col, columns=vibe_col, aggfunc=\"size\", fill_value=0)\n    \n    plt.figure(figsize=(10, 6))\n    sns.heatmap(pivot, annot=True, fmt=\"d\", cmap=\"Blues\")\n    plt.title(\"Number of Songs per Album per Cluster\")\n    plt.xlabel(\"Cluster Vibe\")\n    plt.ylabel(\"Album\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:43:01.563635Z","iopub.execute_input":"2025-04-20T17:43:01.564027Z","iopub.status.idle":"2025-04-20T17:43:01.580903Z","shell.execute_reply.started":"2025-04-20T17:43:01.563989Z","shell.execute_reply":"2025-04-20T17:43:01.579692Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Call the functions we defined above to visualize cluster relationships.\n\nUncomment lines to see different visualization.","metadata":{}},{"cell_type":"code","source":"# Try them all!\n\n# Which clusters make up an album?\n# composition_pie_chart(album_col, vibe_col) \n\n# Which albums make up a cluster?\n# composition_pie_chart(vibe_col, album_col)\n\n# Combination\ncomposition_pivot_table()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:15:25.712431Z","iopub.execute_input":"2025-04-20T18:15:25.712855Z","iopub.status.idle":"2025-04-20T18:15:26.108707Z","shell.execute_reply.started":"2025-04-20T18:15:25.712826Z","shell.execute_reply":"2025-04-20T18:15:26.107497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Time-Cluster Relationship\n\nIn this section, we'll explore how an artist's usage of lyrics belonging to a particular cluster changes over the course of their career. \n\nWe'll aim to answer questions like:\n\n- Does the artist have distinct \"eras\" in which they shift their lyrical themes noticeably over time?\n- How quickly do these lyrical shifts take place? Are the changes sudden or more gradual?","metadata":{}},{"cell_type":"code","source":"# Count songs per cluster per year\ncounts = df.groupby([year_col, vibe_col]).size().reset_index(name='count')\n\n# Pivot to have years as rows and clusters as columns\npivot = counts.pivot(index=year_col, columns=vibe_col, values='count').fillna(0)\n\n# Normalize to get proportions per year\nproportions = pivot.div(pivot.sum(axis=1), axis=0)\n\n# Plot\nproportions.plot.area(colormap='tab10', figsize=(10, 6))\nplt.title(\"Proportion of Clusters in Songs Over Time\")\nplt.ylabel(\"Proportion of Songs\")\nplt.xlabel(\"Year\")\nplt.legend(title=\"Cluster\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:43:02.024228Z","iopub.execute_input":"2025-04-20T17:43:02.024649Z","iopub.status.idle":"2025-04-20T17:43:02.505865Z","shell.execute_reply.started":"2025-04-20T17:43:02.024608Z","shell.execute_reply":"2025-04-20T17:43:02.504859Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluating Cluster Definitions\n\nWe've been using these cluster summaries to find relationships and draw conclusions about trends in lyrics.\n\nNow, we'll evaluate these summaries to see how effectively they capture the theme of the cluster.\n\nTo do this, we'll create new embeddings. However, this time we'll:\n\n- Create `retrieval_query` embeddings for lyrics\n- Create `retrieval_document` embeddings for cluster summaries\n\nWe'll store the `retrieval_document` embeddings in a [Chroma](https://www.trychroma.com/) vector database. We can then query the database using our `retrieval_query` embeddings. \n\nThis means that for any given query, the vector database will return the most semantically similar document that it contains.\n\nIn our case, we'll be querying using the lyrics from a particular songs, and the database will return the most appropriate cluster summary for those lyrics.\n\nWe can compare the cluster summary that is returned from the database to the cluster summary that the lyrics were first assigned. This will give us an idea of how effective these summaries are at capturing the overall sentiment of the lyrics for that particular cluster.\n","metadata":{}},{"cell_type":"markdown","source":"Create a new function for generating embeddings. This function differs from our last function that created embeddings in order to support Chroma's [`EmbeddingFunction` protocol](https://docs.trychroma.com/docs/embeddings/embedding-functions#custom-embedding-functions)","metadata":{}},{"cell_type":"code","source":"from chromadb import Documents, EmbeddingFunction, Embeddings\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    # Specify whether to generate embeddings for documents or queries\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable, timeout=300.0)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            ),\n        )\n        return [e.values for e in response.embeddings]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:43:02.507068Z","iopub.execute_input":"2025-04-20T17:43:02.507454Z","iopub.status.idle":"2025-04-20T17:43:03.177219Z","shell.execute_reply.started":"2025-04-20T17:43:02.507419Z","shell.execute_reply":"2025-04-20T17:43:03.176140Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use the function to create document embeddings for our cluster summary descriptions.","metadata":{}},{"cell_type":"code","source":"import chromadb \n\nembed_fn = GeminiEmbeddingFunction()\n\n# Use document embeddings for cluster descriptions\nembed_fn.document_mode = True \n\n# Collect the summary descriptions as our documents\ndocuments = []\nfor summary in cluster_summaries:\n    documents.append(summary[\"description\"])\n\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=\"cluster_descriptions\", embedding_function=embed_fn)\n\n# Add the descriptions to the database\ndb.add(documents=documents, ids=[str(i) for i in range(len(documents))])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:43:03.178266Z","iopub.execute_input":"2025-04-20T17:43:03.178609Z","iopub.status.idle":"2025-04-20T17:43:03.802654Z","shell.execute_reply.started":"2025-04-20T17:43:03.178573Z","shell.execute_reply":"2025-04-20T17:43:03.801563Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Alright, our cluster summaries are in the database. Let's try out some queries!\n\nChange the `query` variable below with your own text, maybe some sample lyrics. Run the cell and see which cluster summary is most closely associated with that text. Is it what you expected?","metadata":{}},{"cell_type":"code","source":"query = \"Somebody once told me / The world is gonna roll me...\"\n\nresult = db.query(query_texts=[query], n_results=1)\nprint(result[\"documents\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T19:01:30.818855Z","iopub.execute_input":"2025-04-20T19:01:30.819330Z","iopub.status.idle":"2025-04-20T19:01:31.094944Z","shell.execute_reply.started":"2025-04-20T19:01:30.819291Z","shell.execute_reply":"2025-04-20T19:01:31.093640Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we'll run queries like this on each of our lyrics to see which cluster is returned. \n\nWe'd like to keep track of the cluster __number__ that is returned as well, so create a map to access this easily.","metadata":{}},{"cell_type":"code","source":"# Create a map from description to cluster number\ndesc_map = {}\nfor summary in cluster_summaries:\n    desc_map[summary[\"description\"]] = summary[\"number\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:43:04.066474Z","iopub.execute_input":"2025-04-20T17:43:04.066818Z","iopub.status.idle":"2025-04-20T17:43:04.073226Z","shell.execute_reply.started":"2025-04-20T17:43:04.066788Z","shell.execute_reply":"2025-04-20T17:43:04.071745Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create and run the function to query the database for each set of lyrics.\n\n**Note**: Since we're creating the query embeddings serially, this step may take some time. If the progress is stuck, please wait a few minutes, as we may have hit our request quota and need to cool down before trying again.","metadata":{}},{"cell_type":"code","source":"doc_cluster_col = \"document_cluster\"\n\n# Use query embeddings for lyrics\nembed_fn.document_mode = False\n\n# Returns a list of cluster numbers in order of most semantically similar\n@retry.Retry(predicate=is_retriable, timeout=300.0)\ndef get_db_clusters(lyrics: str) -> [int]:\n    # Query the db using the lyrics - Return num_clusters results to see the full similarity order\n    result = db.query(query_texts=[lyrics], n_results=num_clusters)\n\n    # Use the desc_map to find the cluster number for the returned description\n    return [desc_map[doc] for doc in result[\"documents\"][0]]\n\ndf[doc_cluster_col] = df[lyrics_col].progress_apply(get_db_clusters)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:43:04.074312Z","iopub.execute_input":"2025-04-20T17:43:04.074880Z","iopub.status.idle":"2025-04-20T17:43:25.867924Z","shell.execute_reply.started":"2025-04-20T17:43:04.074838Z","shell.execute_reply":"2025-04-20T17:43:25.866881Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We’ve now added a column that contains a list of cluster numbers ordered by decreasing semantic similarity to the song's lyrics. \n\nThe most similar cluster based on description appears first in the list, the second most similar appears second, and so on.\n\nLet's look at this column:","metadata":{}},{"cell_type":"code","source":"df.loc[:,[cluster_col, doc_cluster_col]].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:43:25.869177Z","iopub.execute_input":"2025-04-20T17:43:25.869633Z","iopub.status.idle":"2025-04-20T17:43:25.881344Z","shell.execute_reply.started":"2025-04-20T17:43:25.869593Z","shell.execute_reply":"2025-04-20T17:43:25.880370Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Next, we’ll create a new column that measures how well the cluster summaries reflect the original clustering. \n\nSpecifically, we’ll calculate the index of the original cluster within the ranked list of matches:","metadata":{}},{"cell_type":"code","source":"df['accuracy_index'] = df.apply(lambda row: row[doc_cluster_col].index(str(row[cluster_col])), axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:43:25.882530Z","iopub.execute_input":"2025-04-20T17:43:25.882891Z","iopub.status.idle":"2025-04-20T17:43:25.901304Z","shell.execute_reply.started":"2025-04-20T17:43:25.882864Z","shell.execute_reply":"2025-04-20T17:43:25.900306Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This index tells us how close the original cluster summary was to being the best semantic match for the song. \n\nA accuracy_index of 0 means the original cluster summary was the top match, indicating that the summary is accurate. Higher values suggest the original summary didn’t align as closely with the lyrics.\n\nNow let’s visualize the distribution of these indices to get a sense of how well our summaries performed:","metadata":{}},{"cell_type":"code","source":"# Ignore warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*use_inf_as_na.*\")\n\nsns.histplot(df['accuracy_index'], bins=range(df['accuracy_index'].max() + 2), discrete=True)\nplt.xlabel('Index of Cluster Number in Ranked List')\nplt.ylabel('Count')\nplt.title('Distribution of Cluster Indices')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:43:25.905444Z","iopub.execute_input":"2025-04-20T17:43:25.905844Z","iopub.status.idle":"2025-04-20T17:43:26.232125Z","shell.execute_reply.started":"2025-04-20T17:43:25.905808Z","shell.execute_reply":"2025-04-20T17:43:26.230678Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n\nIn this notebook, we attempted to identify whether artists have distinctive creative \"eras\" with their lyrics, similar to what Taylor Swift fans have seen with her discography.\n\nWe clustered song lyrics into semantically similar groupings and identified the general sentiment of the lyrics in each group. \n\nWe explored how these clusters related to albums and release years and we even performed an evaluation on the cluster summaries to see how effectively they conveyed the message of the lyrics. \n\nWe leveraged several AI capabilities in order to accomplish this, including:\n\n- Embeddings (`clustering`, `retrieval_query`, and `retrieval_document`)\n- Few-shot Prompting\n- Structured output with JSON\n- Vector databases and querying\n\nSo, back to our original question:\n\n**Could every artist have an Eras Tour of their own?**\n\nThe results seem to indicate that while artists tend to have a handful of common themes in their lyrics, they're not always as distinct and well-defined as we may believe. \n\nClusters generally varied across albums and through different time periods, with a few exceptions that are worth noting. In many cases, even after \"leaving\" a particular era, an artist would typically find their way back to those lyrical themes at some point. \n\nIt's important to note that our analysis has its limitations:\n\n- A small sample size of only a couple artists (and only one at a time)\n- Analysis was done using lyrics only, which cannot capture the entire essence of a song\n- AI models still have room for improvement, especially with potentially abstract inputs like song lyrics\n\nWe can draw certain conclusions from the data we have, but ultimately these limitations prevent us from making any broad claims about musicians and the lyrics in general.\n\nIn the future, we could address these limitations to make this analysis more robust. We could even extend the project to include things like:\n\n- Comparison of eras between artists\n- Contexualization of eras by including information about the musical and societal landscape at the time of release\n- Comparison of AI-defined eras with fan-defined eras\n\nThanks for reading!","metadata":{}},{"cell_type":"markdown","source":"## Citations\n\nMany of the code snippets in this notebook were taken and/or derive from those found in the [Google 5-Day Gen AI Intensive Course CodeLabs](https://www.kaggle.com/learn-guide/5-day-genai).\n\nSome code snippets were also taken from the Gemini documentation and [tutorials](https://github.com/google/generative-ai-docs/tree/main/site/en/gemini-api/tutorials).","metadata":{}}]}